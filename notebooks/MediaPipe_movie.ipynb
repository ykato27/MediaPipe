{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリーのインストール\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期設定\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# Initialize MediaPipe Holistic.\n",
    "holistic = mp_holistic.Holistic(\n",
    "    static_image_mode=True, min_detection_confidence=0.5)\n",
    "\n",
    "# Prepare DrawingSpec for drawing the face landmarks later.\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ビデオの指定\n",
    "video_path = './movie/sample_movie.mp4'\n",
    "video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 既にimagesフォルダーがあれば削除\n",
    "if os.path.isdir('./movie/images'):\n",
    "    shutil.rmtree('./movie/images')\n",
    "os.makedirs('./movie/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_2_images(video_file= video_path, \n",
    "                   image_dir='./movie/images/', \n",
    "                   image_file='img_%s.png'):\n",
    " \n",
    "    # Initial setting\n",
    "    i = 0\n",
    "    interval = 3\n",
    "    length = 300\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    while(cap.isOpened()):\n",
    "        flag, frame = cap.read()  \n",
    "        if flag == False:\n",
    "            break\n",
    "        if i == length*interval:\n",
    "            break\n",
    "        if i % interval == 0:\n",
    "            cv2.imwrite(image_dir+image_file % str(i).zfill(6), frame)\n",
    "        i += 1 \n",
    "    cap.release()  \n",
    "\n",
    "def main():\n",
    "    video_2_images()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image file names to files in list format\n",
    "files=[]\n",
    "for name in sorted(glob.glob('./movie/images/*.png')):\n",
    "    files.append(name)\n",
    "\n",
    "# Read images with OpenCV.\n",
    "images = {name: cv2.imread(name) for name in files}\n",
    "\n",
    "for name, image in images.items():\n",
    "    # Convert the BGR image to RGB and process it with MediaPipe Pose.\n",
    "    results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Draw pose landmarks.\n",
    "    annotated_image = image.copy()\n",
    "    mp_drawing.draw_landmarks(annotated_image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(annotated_image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image=annotated_image, \n",
    "        landmark_list=results.face_landmarks, \n",
    "        connections=mp_holistic.FACE_CONNECTIONS,\n",
    "        landmark_drawing_spec=drawing_spec,\n",
    "        connection_drawing_spec=drawing_spec)\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image=annotated_image, \n",
    "        landmark_list=results.pose_landmarks, \n",
    "        connections=mp_holistic.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec=drawing_spec,\n",
    "        connection_drawing_spec=drawing_spec)\n",
    "    cv2.imwrite(name, annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob.glob('./movie/images/*.png'))\n",
    "images = list(map(lambda file: Image.open(file), files))\n",
    "images[0].save('./movie/out.gif', save_all=True, \n",
    "               append_images=images[1:], \n",
    "               duration=100, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display gif\n",
    "from IPython.display import Image\n",
    "Image('./movie/out.gif', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
